{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Read in data for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AllData=pd.read_csv('K:\\Rainshelter\\Wheat 2015-16\\LoggedData\\RainShelterAlpha_CS650.dat', #specify file path for data to read in\n",
    "                         parse_dates=True, #tell the function to parse date columns to datetime formats\n",
    "                         dayfirst=True, #tell the function that the day is before the year in the data i.e format='%d/%m/%Y %H:%M'\n",
    "                         skiprows = [0,2,3], #leave out rows 1, 3 and 4 which have redundant information\n",
    "                         index_col = 0, #Use the first column, which is Date, as an index\n",
    "                         na_values = 'NAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Apply indexing for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Bring in index data\n",
    "AllDataIndex=pd.read_csv('C:\\GitHubRepos\\RainShelterWheat\\IndexFiles\\SoilWaterAndTempIndex.csv',\n",
    "                         index_col = 0)\n",
    "#Apply indexes to data\n",
    "AllDataTransposed = AllData.transpose()\n",
    "AllDataIndexed = pd.concat([AllDataIndex,AllDataTransposed], axis=1)\n",
    "AllDataIndexed.index.name='ColumnHeader'\n",
    "AllDataIndexed.set_index(['Measurement','Depth','Nitrogen','Irrigation','Plot','Sensor', 'MUX', 'Port','Units','Summary','Block','Treatment'], \n",
    "                        append=False, inplace=True)\n",
    "AllDataIndexed.sort(inplace=True)\n",
    "FieldData=AllDataIndexed.transpose()\n",
    "FieldData.index = FieldData.index.to_datetime()  ## for some reason the concat function changes the data type on the date indes so need to change it back\n",
    "\n",
    "#Record the last row number read in\n",
    "LastRow = FieldData.index.size\n",
    "np.save('LastRow.npy',LastRow)\n",
    "FieldData.to_pickle('.\\FieldData.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Bring in libraries and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "import time \n",
    "from plotly.graph_objs import *\n",
    "%matplotlib inline\n",
    "tls.set_credentials_file(username='HamishBrown',\n",
    "                         api_key='wdly9f0kob', \n",
    "                         stream_ids=['vb2iyh03io','b3ups5mc5b','l7xzuy9x4w','3tehbozomt','u7zloau0q6','rpbftetm6d','4e70vk8kvi'],\n",
    "                         proxy_username='cflhxb', \n",
    "                         proxy_password='wakanui/9')\n",
    "Tokens = tls.get_credentials_file()['stream_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Function to read in fresh data and update status files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Bring in date recorded since last update\n",
    "def UpdataDataFrame():\n",
    "    #Bring in previous status files\n",
    "    LastRead = np.load('.\\LastRow.npy')\n",
    "    FieldData = pd.read_pickle('.\\FieldData.pkl')\n",
    "    #Bring in index data\n",
    "    AllDataIndex=pd.read_csv('C:\\GitHubRepos\\RainShelterWheat\\IndexFiles\\SoilWaterAndTempIndex.csv',\n",
    "                         index_col = 0)\n",
    "    \n",
    "    #Bring in fresh data\n",
    "    StartRead = LastRead + 4\n",
    "    Skips = [0,2,3] + range(4,StartRead)\n",
    "    FreshData=pd.read_csv('K:\\Rainshelter\\Wheat 2015-16\\LoggedData\\RainShelterAlpha_CS650.dat', #specify file path for data to read in\n",
    "                             parse_dates=True, #tell the function to parse date columns to datetime formats\n",
    "                             dayfirst=True, #tell the function that the day is before the year in the data i.e format='%d/%m/%Y %H:%M'\n",
    "                             skiprows = Skips, #rows that have already be read\n",
    "                             index_col = 0, #Use the first column, which is Date, as an index\n",
    "                             na_values = 'NAN')\n",
    "\n",
    "    #Apply indexes to fresh data\n",
    "    FreshDataTransposed = FreshData.transpose()\n",
    "    FreshDataIndexed = pd.concat([AllDataIndex,FreshDataTransposed], axis=1)\n",
    "    FreshDataIndexed.index.name='ColumnHeader'\n",
    "    FreshDataIndexed.set_index(['Measurement','Depth','Nitrogen','Irrigation','Plot','Sensor', 'MUX', 'Port','Units','Summary','Block','Treatment'], \n",
    "                            append=False, inplace=True)\n",
    "    FreshDataIndexed.sort(inplace=True)\n",
    "    NewData=FreshDataIndexed.transpose()\n",
    "    \n",
    "    #Join fresh data onto existing data\n",
    "    FieldData = pd.concat([FieldData,NewData])\n",
    "    FieldData.sort_index(inplace = True)\n",
    "    \n",
    "    #Update status files\n",
    "    LastRow = FieldData.index.size\n",
    "    np.save('LastRow.npy',LastRow)\n",
    "    FieldData.to_pickle('.\\FieldData.pkl')\n",
    "    return FieldData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Build base Plotly Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~HamishBrown/168.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creat class with treatment data\n",
    "\n",
    "class Treatment(object):\n",
    "    def __init__(self, Number, Irrigation, Nitrogen):\n",
    "        self.Number=Number\n",
    "        self.Irrigation=Irrigation\n",
    "        self.Nitrogen=Nitrogen\n",
    "        self.streamID=Tokens[number]\n",
    "        self.Label= Irrigation + ' ' + Nitrogen + 'N'\n",
    "        self.Trace = Scatter(x=[],y=[], name = self.Label,\n",
    "                stream = Stream(token=self.streamID)\n",
    "                )\n",
    "        self.Stream = py.Stream(self.streamID)\n",
    "\n",
    "Treatments = []\n",
    "Colors = ['red','blue','green']\n",
    "NRates = ['0','50','250']\n",
    "IRates = ['Dryland','Irrigated']\n",
    "Lines = ['solid','dash']\n",
    "number = 0\n",
    "LinePos = 0\n",
    "for I in IRates:\n",
    "    ColorPos = 0\n",
    "    for N in NRates:\n",
    "        Treatments.append(Treatment(number, I, N))\n",
    "        Treatments[number].Trace.line = Line(color = Colors[ColorPos], dash = Lines[LinePos])\n",
    "        ColorPos +=1\n",
    "        number += 1\n",
    "    LinePos+=1\n",
    "    \n",
    "GraphData = Data([Treatments[0].Trace,\n",
    "                  Treatments[1].Trace,\n",
    "                  Treatments[2].Trace,\n",
    "                  Treatments[3].Trace,\n",
    "                  Treatments[4].Trace,\n",
    "                  Treatments[5].Trace\n",
    "                 ])\n",
    "\n",
    "py.iplot(GraphData, filename = 'RainShelterWheat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Function to Updata data frame and traces and stream to Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Update():\n",
    "    #Update Data Frame with data that has been logged since last update\n",
    "    FieldData = UpdataDataFrame()\n",
    "    #Calculate treatment means omitting data prior to 2014-11-05 08:00:00 to avoid NaN values\n",
    "    DataMeans =  FieldData.ix['2015-10-10':].groupby(level=['Measurement','Depth','Irrigation', 'Nitrogen'],axis=1).mean()\n",
    "    DataMeans =  DataMeans.dropna(axis=1) #For some reason it keeps non valid combinations in so need to extract with this function\n",
    "\n",
    "    #Calculate the water content of the soil profile by multiplying the volumetric water content by each layers\n",
    "    #depth and summing.  The 0-15 layers are divided by 2 to average the two readings\n",
    "    ProfileWater = DataMeans.VolumetricWaterContent.ix[:,'D1I'] * 150/2 + \\\n",
    "                   DataMeans.VolumetricWaterContent.ix[:,'D1B'] * 150/2 + \\\n",
    "                   DataMeans.VolumetricWaterContent.ix[:,'D2'] * 150 + \\\n",
    "                   DataMeans.VolumetricWaterContent.ix[:,'D3'] * 300 + \\\n",
    "                   DataMeans.VolumetricWaterContent.ix[:,'D4'] * 300 + \\\n",
    "                   DataMeans.VolumetricWaterContent.ix[:,'D5'] * 300 + \\\n",
    "                   DataMeans.VolumetricWaterContent.ix[:,'D6'] * 300 + \\\n",
    "                   DataMeans.VolumetricWaterContent.ix[:,'D7'] * 300\n",
    "\n",
    "    FieldCapacity = ProfileWater.resample('D', how='max')\n",
    "    FieldCapacity = FieldCapacity.ix['2015-10-14'] +30 # I would have though this would return a data frame with a single row but instead it returns a series with a multiindex in columns\n",
    "    SoilWaterDeficit = -(FieldCapacity - ProfileWater)    # This calculation only works because field capacity is a multi index series\n",
    "\n",
    "    X = SoilWaterDeficit.index\n",
    "    for Treatment in Treatments:\n",
    "        Treatment.Stream.open()\n",
    "        Treatment.Stream.write({'x':X,'y':SoilWaterDeficit.ix[:,(Treatment.Irrigation,Treatment.Nitrogen)]})\n",
    "        Treatment.Stream.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Continious update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    Update()\n",
    "    time.sleep(900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##One off update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
